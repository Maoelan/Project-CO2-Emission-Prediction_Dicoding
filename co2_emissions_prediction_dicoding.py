# -*- coding: utf-8 -*-
"""CO2 Emissions - Prediction - Dicoding

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bGLTwTu1wII9QX_1hTthoxAM4ubRR7zR

**Import Library / Dependencies**
"""

#import library
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

from sklearn.metrics import mean_squared_error

"""# **Load Dataset**


---

DATASET : https://www.kaggle.com/datasets/debajyotipodder/co2-emission-by-vehicles
"""

#load dataset
data = pd.read_csv('/content/drive/MyDrive/dataset/archive (11)/CO2 Emissions_Canada.csv')

data

"""# **Exploratory Data Analysis**


---


"""

data.info()

"""Dari hasil info tersebut dapat disimpulkan bahwa:
*   Terdapat 5 feature dengan tipe categorical atau object yaitu Make, Model, Vehicle Class, Transmission, dan Fuel Type
*   Terdapat 7 feature dengan tipe numeric terdiri dari 4 float64 yaitu Engine Size(L), Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), dan 3 bertipe int64 yaitu Cylinders, Fuel Consumption Comb (mpg) dan CO2 Emissions(g/km)

Deskripsi Variabel

*   Make : Perusahaan yang membuat kendaraan
*   Model : Model dari kendaraan
*   Vehicle Class : Kelas dari kendaraan berdasarkan utilitas, kapasitas dan berat 
*   Engine Size (L) : Ukuran dari mesin dalam satuan liter (L)
*   Cylinders : Jumlah silinder kendaraan (ruang naiknya piston)
*   Transmission : Tipe transmisi dengan jumlah gigi kendaraan
 *   A = Otomatis
 *   AM = Manual Otomatis
 *   AS = Otomatis dengan pilihan shift
 *   AV = Variabel kontinu
 *   M = Manual
 *   X = Angka dari gigi
*   Fuel Type : Tipe bahan bakar
 *   X = Bensin Reguler
 *   Z = Bensin Premium
 *   D = Disel
 *   E = Ethanol (E85)
 *   N = Gas Natural
*   Fuel Consumption City (L/100 km) : Jumlah konsumsi bahan bakar dijalanan kota dalam satuan (L/100 km)
*   Fuel Consumption City (L/100 km) : Jumlah konsumsi bahan bakar dijalanan raya dalam satuan (L/100 km)
*   Fuel Consumption Comb (L/100 km) : Jumlah konsumsi bahan bakar (55% kota. 45% jalan raya) dalam satuan (L/100 km)
*   CO2 Emissions(g/km) : Emisi knalpot karbon dioksida dalam gram/kilometer (g/km) dari gabungan berkendara pada jalanan kota dan jalan raya
"""

#Menghapus feature yang dianggap kurang penting untuk model
data = data.drop(['Make', 'Model', 'Vehicle Class'], axis = 1)

"""Mengapa menghapus feature Make, Model dan Vehicle Class?


*   Make : karena ini hanya berisi info nama perusahaan yang membuat kendaraan
*   Model : ini hanya menjelaskan model dari kendaraan
*   Vehicle class : Ini hanya mengkriteriakan model berdasarkan utiliti, kapasitas dan besar lebar kursi penumpang




"""

#Cek nilai Null
print(data.isna().sum())

#Cek deskripsi stastik data
data.describe()

"""Terlihat pada stastitik data bahwa tidak ada kejanggalan dari data stastik yang ditampilkan. Tetapi dapat dilihat pada beberapa feature terdapat gap atau jarak yang lumayan jauh antara nilai pada kuartil ketiga dengan nilai maksimum. Ditakutan ini merupakan data outlier."""

#Cek data outlier
num_feat = ['Engine Size(L)', 'Cylinders', 'Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']
cat_feat = ['Transmission', 'Fuel Type']

for num in num_feat :
  plt.figure(figsize = (10,5))
  sns.boxplot(data = data, x = num, palette = 'Set1')
  plt.figure()

"""Seperti yang diduga-duga sebelumnya, setelah melakukan visualisasi data menggunakan boxplot terlihat bahwa terdapat data outlier, untuk menghilangkan data outlier, pada kasus ini menggunakan IQR Method"""

#IQR Method | Menghapus outlier
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)

IQR = Q3 - Q1

data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]

data.shape

"""Setelah menghapus data outlier & menghapus beberapa feature, data yang tadinya sebanyak 7385 x 12 sekarang menjadi 6826 x 9

**Unvariate Analysis**
"""

feature = cat_feat[0] 
count = data[feature].value_counts()

#Categorical
percent = 100 * data[feature].value_counts(normalize = True)
df = pd.DataFrame({'Jumlah sample' : count, 'Persentase' : percent.round(1)})
print(df)
plt.figure(figsize = (15,5))
sns.countplot(x = feature, data = data, palette = 'gist_rainbow', order = data['Transmission'].value_counts().index)

"""Terdapat 27 kategori feature untuk transmission dapat disimpulkan:
*   Transmisi AS (Otomatis dengan pilihan shift) sebanyak 43.6%
*   Transmisi A (Otomatis) sebanyak 23.8%
*   Transmisi M (Manual) sebanyak 17%
*   Transmisi AM (Manual Otomatis) sebanyak 8.2%
*   Transmisi AV (Variabel kontinu) sebanyak 7.2%

Hampir setengah dari total kendaraan memiliki tipe transmisi AS atau otomatis dengan pilihan shift yaitu sebanyak 43.6%

"""

feature = cat_feat[1]
count = data[feature].value_counts()
percent = 100 * data[feature].value_counts(normalize = True)
df = pd.DataFrame({'Jumlah sample' : count, 'Persentase' : percent.round(1)})
print(df)
sns.countplot(x = feature, data = data, palette = 'gist_rainbow', order = data['Fuel Type'].value_counts().index)

"""Pada Fuel Type terdapat 5 jenis variabel yaitu X, Z, E, D dan N. Dapat disimpulkan bahwa sebagian besar kendaraan menggunakan Fuel Type X dan Z yaitu Bensin Reguler dan Bensin Premium dengan persentase 94.1%"""

#Numeric
data.hist(bins = 20, figsize = (15, 15), color = "crimson", grid = False)
plt.show()

"""Pada histogram diatas khususnya pada feature CO2 Emissions(g/km) dapat disimpulkan bahwa:
*   Peningkatan CO2 Emission sebanding dengan peningkatan jumlah sample. Dapat terlihat pada histogram feature "CO2 Emission" grafik mengalami peningkatan dengan semakin banyaknya sample
*   Kadar CO2 Emission yang dihasilkan 2x dari batas normal yaitu 522 g/km
*   Setengah kadar CO2 Emission berada pada kisaran 246 g/km
*   Kebanyakan kadar C02 Emission terdapat pada quartil ke-1 sampai ke-3
*   Distribusi CO2 Emission miring kekanan (left-skewed) yang berarti nilai median (nilai tengah) terdapat pada quartile ke-3 dan lebih besar dari nilai rata-rata

**Multivariate Analysis**
"""

#Categorical
categorical = data.select_dtypes(include = 'object').columns.to_list()

for col in cat_feat :
  sns.catplot(x = col, y = 'CO2 Emissions(g/km)', kind = 'bar', dodge = False, height = 4, aspect = 3, data = data, palette = 'gist_rainbow')
  plt.title("Rata - rata CO2 Emissions(g/km) terhadap - {}".format(col))

"""Pada visualisasi terhadap fitur kategori, dapat disimpulkan:
*   Rentang CO2 Emission pada tiap tipe transmission berkisar pada 140 - 300, dapat dilihat distribusi data tidak mengalami penurunan maupun peningkatan yang membuktikan kalau fitur transmission memiliki dampak kecil terhadap CO2 Emission
*   Rentang CO2 Emission pada Fuel Type berada diatas 200 sampai dengan 250, dimana tiap Fuel Type memiliki kemiripan dan rentang yang tidak terlalu berselisih jauh yang membuktikan kalau fitur Fuel Type memiliki dampat kecil terhadap CO2 Emission


"""

#Numeric
sns.pairplot(data, diag_kind = 'kde')

"""Pola sebaran data pada grafik pairplot diatas terlihat bahwa semua feature memiliki korelasi yang tinggi terhadap feature CO2 Emission. Berikut merupakan kesimpulan dari korelasi pairplot diatas:
* Engine Size(L) : Positive Correlation
* Cylinders : Positive Correlation
* Fuel Consumption City (L/100 km) : Positive Correlation
* Fuel Consumption Hwy (L/100 km) : Positive Correlation
* Fuel Consumption Comb (L/100 km) : Positive Correlation
* Fuel Consumption Comb (mpg) : Negative Correlation

Untuk membuktikan hal tersebut dapat dilakukan evaluasi skor korelasi menggunakan fungsi corr() seperti dibawah


"""

#Skor korelasi
plt.figure(figsize = (10,8))
correlation_matrix = data.corr().round(2)

sns.heatmap(data = correlation_matrix, annot = True, cmap = 'rocket_r')
plt.title("Correlation Matrix untuk Fitur Numerik ", size = 14)

"""Terbukti apabila rata-rata feature memiliki korelasi dengan CO2 Emissions yang rata-rata skor korelasi diatas 0.8 untuk positive correlation, dan -0.9 untuk negative correlation, sehingga tidak ada feature yang perlu dihapus

# **Data Preparation**

---

**Encoding Fitur Kategori**
"""

#LabelEncoder
le = LabelEncoder()
le.fit(data['Transmission'])
data['Transmission'] = le.transform(data['Transmission'])
transmission_labels = dict(zip(le.classes_, le.transform(le.classes_)))
print(transmission_labels)

"""Mengubah categorical pada feature Transmission menjadi numerik agar lebih baik diproses oleh model menggunakan LabelEncoder"""

#OneHotEncoder
data = pd.concat([data, pd.get_dummies(data['Fuel Type'], prefix = 'Fuel_Type')], axis = 1)

"""Melakukan OneHotEncoder pada feature Fuel Type agar mendapatkan feature baru berdasarkan nilai dari Fuel Type yang mewakili variabel kategori Fuel Type"""

data

"""**Reduksi Dimensi menggunakan PCA**"""

sns.pairplot(data[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']], plot_kws = {'s' : 3})

"""Pada pairplot diatas terlihat kalau ketiga feature yaitu Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km) dan Fuel Consumption Comb (L/100 km) memiliki korelasi yang cukup tinggi sehingga dapat dilakukan proses reduksi dimensi"""

#PCA
pca = PCA(n_components = 3, random_state = 50)
pca.fit(data[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])
princ_comp = pca.transform(data[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])

pca.explained_variance_ratio_.round(3)

"""Dapat dilihat kalau 98.2% informasi dari ketiga fitur tersebut terdapat pada PCA pertama, sehingga reduksi dimensi akan mempertahankan PC yang pertama menggantikan ketiga fitur tersebut. Ketiga fitur tersebut akan digantikan dengan fitur baru bernama Fuel Consumption seperti yang terlihat dibawah"""

pca = PCA(n_components = 1, random_state = 50)
pca.fit(data[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])
data['Fuel Consumption'] = pca.transform(data.loc[:, ('Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)')]).flatten()
data.drop(['Fuel Type','Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)'], axis = 1, inplace = True)

data

data.info()

"""**Train-Test-Split**

Sebelum dilakukan train-test-split, langkah awal adalah memisahkan antara feature dan label, variabel x digunakan untuk menampung feature yang tediri dari:
*   Engine Size(L)
*   Cylinders
*   Transmission
*   Fuel Consumption Comb (mpg)
*   Fuel_Type_D
*   Fuel_Type_E
*   Fuel_Type_N
*   Fuel_Type_X
*   Fuel_Type_Z
*   Fuel Consumption

Dan variabel x digunakan untuk menampung label yaitu 
*   CO2 Emissions(g/km)

Kemudian akan dilakukan pembagian data sebesar 80:20 dengan train_test_split
"""

#x,y
x = data.drop(['CO2 Emissions(g/km)'], axis = 1)
y = data['CO2 Emissions(g/km)']

#train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100)

print(f'Total sample in whole dataset : {len(x)}')
print(f'Total sample in trian dataset : {len(x_train)}')
print(f'Total sample in test dataset : {len(x_test)}')

"""Dapat dilihat dari total 6826 data setelah dilakukan splitting data, data terbagi menjadi 5460 train dan 1366 test

**Standarisasi**
"""

#Standarisasi MinMaxScaler
num_feat = ['Engine Size(L)', 'Cylinders', 'Transmission', 'Fuel Consumption Comb (mpg)']
scaler = MinMaxScaler()
scaler.fit(x_train[num_feat])
x_train[num_feat] = scaler.transform(x_train.loc[:, num_feat])
x_train[num_feat]

x_train[num_feat].describe().round(4)

"""Setelah dilakukan standarisasi dengan MinMaxScaler dapat terlihat bahwa min dari data yaitu 0 dan max dari data yaitu 1, karena standarisasi MinMaxScaler menghasilkan distribusi data yang ada pada rentang 0 dan 1

# **Model Development**

---

Pada tahapan model development ini algoritma machine learning yang digunakan terdiri dari:

1. Linear Regression
2. Decision Tree Regression
3. SVM
4. KNN
5. Random Forest
6. Boosting
"""

#Dataframe untuk analisis model
models = pd.DataFrame(index = ['train_mse', 'test_mse'],
                      columns = ['LinearRegressor', 'DecisionTreeRegressor', 'KNN', 'RandomForest', 'Boosting'])

"""**Model Training**"""

#Melatih data dengan LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(x_train, y_train)

models.loc['train_mse', 'LinearRegressor'] = mean_squared_error(y_pred = lin_reg.predict(x_train), y_true = y_train)

#Melatih data dengan DecisionTreeRegressor
DTR = DecisionTreeRegressor(max_depth = 10, random_state = 20)
DTR.fit(x_train, y_train)

models.loc['train_mse', 'DecisionTreeRegressor'] = mean_squared_error(y_pred = DTR.predict(x_train), y_true = y_train)

"""Penjelasan paramater
* max_depth = 10 : kedalaman pohon
* random_state = 20 : digunakan untuk random generator
"""

#Melatih data dengan K-Nearest Neighbor
KNN = KNeighborsRegressor(n_neighbors = 7)
KNN.fit(x_train, y_train)

models.loc['train_mse', 'KNN'] = mean_squared_error(y_pred = KNN.predict(x_train), y_true = y_train)

"""Penjelasan parameter
* n_neighbors = 7 : jumlah tetangga yang digunakan untuk mengukur jarak
"""

#Melatih data dengan LinearRegression
RF = RandomForestRegressor(n_estimators = 50, max_depth = 15, random_state = 55, n_jobs = -1)
RF.fit(x_train, y_train)

models.loc['train_mse', 'RandomForest'] = mean_squared_error(y_pred = RF.predict(x_train), y_true = y_train)

"""Penjelasan parameter
* n_estimators = 50 : jumlah tree pada forest
* max_depth = 15 : kedalaman pohon
* random_state = 55 : digunakan untuk random generator
* n_jobs = -1 : jumlah job yang digunakan secara pararel
"""

#Melatih data dengan Ada Boosting Regressor
boosting = AdaBoostRegressor(learning_rate = 0.9, random_state = 50, n_estimators = 10)
boosting.fit(x_train, y_train)
models.loc['train_mse', 'Boosting'] = mean_squared_error(y_pred = boosting.predict(x_train), y_true = y_train)

"""Penjelasan parameter
* learning_rate = 0.9 : bobot pada regressor pada masing-masing iterasi
* random_state = 50 : digunakan untuk random generator
* n_estimators = 10 : jumlah base estimator yang ingin digunakan dalam data

**Evaluasi Model**
"""

x_test.loc[:, num_feat] = scaler.transform(x_test[num_feat])

"""Sebelum menghitung MSE pada model, perlu dilakukan scaling terlebih dahulu pada data uji"""

#Model Evaluation
mse = pd.DataFrame(columns = ['train', 'test'], index = ['LinearRegressor', 'DecisionTreeRegressor', 'KNN', 'RandomForest', 'Boosting'])

model_dict = {'LinearRegressor' : lin_reg, 'DecisionTreeRegressor' : DTR, 'KNN' : KNN, 'RandomForest' : RF, 'Boosting' : boosting}

for name, model in model_dict.items() :
  mse.loc[name, 'train'] = mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))/1e3
  mse.loc[name, 'test'] = mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))/1e3
mse

fig, ax = plt.subplots()
mse.sort_values(by = 'test', ascending = False).plot(kind = 'barh', ax = ax, zorder = 3)
ax.grid(zorder = 0)

"""Diperhatikan pada tabel diatas dapat dilihat bahwa model Random Forest memberikan error yang paling kecil diikuti dengan Decision Tree, KNN, dan LinearRegression, kemudian model Boosting memiliki error yang paling besar

Untuk menguji model yang telah dilatih, disini akan dilakukan proses prediksi menggunakan CO2 Emission pada data test
"""

prediksi = x_test.iloc[:1].copy()
pred_dict = {'y_true' : y_test[:1]}
for name, model in model_dict.items() :
  pred_dict['prediksi_' + name] = model.predict(prediksi).round(2)

pd.DataFrame(pred_dict)

"""Dapat dilihat pada hasil prediksi data test diatas dapat disumpulkan:
*   Model Random Forest mendapatkan prediksi paling tepat dengan nilai 207.88
*   Model Decision Tree mendapatkan prediksi 207.83
*   Model KNN mendapatkan prediksi 207.71
*   Model Linear Regression mendapatkan prediksi 207.0
*   Model Ada Boosting mendapatkan prediksi 216.71

Dapat disumpulkan bahwa hasil prediksi sesuai dengan tabel error yang ditampilkan diatas


"""